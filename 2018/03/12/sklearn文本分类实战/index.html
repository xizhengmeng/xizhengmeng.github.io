<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python,sklearn,文本分类,自然语言," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2" />






<meta name="description" content="训练步骤  数据集合 文本分词 去除停用词，低频词 抽取特征 计算特征向量权值 训练分类器  使用模型步骤  文本分词 去除停用词，低频词 计算特征向量权值 使用模型进行分类">
<meta name="keywords" content="python,sklearn,文本分类,自然语言">
<meta property="og:type" content="article">
<meta property="og:title" content="sklearn中文文本分类实战">
<meta property="og:url" content="/2018/03/12/sklearn文本分类实战/index.html">
<meta property="og:site_name" content="Hanson的博客">
<meta property="og:description" content="训练步骤  数据集合 文本分词 去除停用词，低频词 抽取特征 计算特征向量权值 训练分类器  使用模型步骤  文本分词 去除停用词，低频词 计算特征向量权值 使用模型进行分类">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-03-19T06:35:49.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="sklearn中文文本分类实战">
<meta name="twitter:description" content="训练步骤  数据集合 文本分词 去除停用词，低频词 抽取特征 计算特征向量权值 训练分类器  使用模型步骤  文本分词 去除停用词，低频词 计算特征向量权值 使用模型进行分类">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="/2018/03/12/sklearn文本分类实战/"/>


  <title> sklearn中文文本分类实战 | Hanson的博客 </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Hanson的博客</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                sklearn中文文本分类实战
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-03-12T10:52:40+08:00" content="2018-03-12">
              2018-03-12
            </time>
          </span>

          

          
            
          

          

          
          

          
              &nbsp; | &nbsp;
              <span class="page-pv"><i class="fa fa-file-o"></i>
              <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
              </span>
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>训练步骤</p>
<ul>
<li>数据集合</li>
<li>文本分词</li>
<li>去除停用词，低频词</li>
<li>抽取特征</li>
<li>计算特征向量权值</li>
<li>训练分类器</li>
</ul>
<p>使用模型步骤</p>
<ul>
<li>文本分词</li>
<li>去除停用词，低频词</li>
<li>计算特征向量权值</li>
<li>使用模型进行分类</li>
</ul>
<a id="more"></a>
<h3 id="去除停用词和低频词"><a href="#去除停用词和低频词" class="headerlink" title="去除停用词和低频词"></a>去除停用词和低频词</h3><p>因为在自然语言中每个词代表一个特征，所以自然语言注定了是一种超高纬特征的机器学习问题，但是在分类问题中很多词是不具备分类能力的，比如，啊，我等等，这些是要去除的停用词，这些词语在不同场景下可以是通用的。另外就是要去除低频词，如果某些词在在整个训练数据集中只出现了一两次，那么这样的特征将会导致表示向量大量的0000存在，是徒增加计算成本而不会对精准分类有什么贡献，所以最好的办法就是直接忽略这些词。</p>
<p>具体在sklearn中我们用到的是<code>from sklearn.feature_extraction.text import CountVectorizer</code>这个类</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vectorizer = CountVectorizer(vocabulary=vocabularyDic,stop_words=[&apos;中国&apos;],token_pattern=u&apos;(?u)\w+&apos;,max_features=200)</div></pre></td></tr></table></figure>
<p>那么是不是使用stop_words这个参数呢，这个要区分，如果是英文文本分类是可以的，但是中文不行，这就是坑啊，所以中文去除停用词只能靠自己。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">def translate(comment):</div><div class="line">    testline = re.sub(u&quot;[\s+\.\!\/_,$%^*(+\&quot;\&apos;]+|[+——！，！。？、~@#￥%……&amp;*（）]+&quot;, &apos;&apos;, comment)</div><div class="line">    testline = testline.replace(chr(32),&apos;&apos;).replace(u&apos;！&apos;, u&apos;&apos;).replace(u&apos;，&apos;, u&apos;&apos;).replace(u&apos;。&apos;, u&apos;&apos;).replace(u&apos;\n&apos;, u&apos;&apos;).replace(u&apos;\t&apos;, u&apos;&apos;).replace(</div><div class="line">        u&apos;?&apos;, u&apos;&apos;).replace(u&apos;【&apos;,&apos;&apos;).replace(u&apos;o&apos;,&apos;&apos;).replace(u&apos;O&apos;,&apos;&apos;).replace(u&apos;丶&apos;,&apos;&apos;).replace(u&apos;‘&apos;,&apos;&apos;).replace(&apos;:&apos;,&apos;&apos;).replace(u&apos;：&apos;,&apos;&apos;).replace(&apos;(&apos;,&apos;&apos;).replace(&apos;)&apos;,&apos;&apos;).replace(&apos;&#123;&apos;,&apos;&apos;).replace(&apos;&#125;&apos;,&apos;&apos;).replace(u&apos;？&apos;, u&apos;&apos;).replace(u&apos;-&apos;,&apos;&apos;).replace(u&apos;一&apos;,&apos;1&apos;).replace(u&apos;二&apos;,&apos;2&apos;).replace(u&apos;三&apos;,&apos;3&apos;).replace(u&apos;四&apos;,&apos;4&apos;).replace(u&apos;五&apos;,&apos;5&apos;).replace(u&apos;六&apos;,&apos;6&apos;).replace(u&apos;七&apos;,&apos;7&apos;).replace(u&apos;八&apos;,&apos;8&apos;).replace(u&apos;九&apos;,&apos;9&apos;).replace(u&apos;零&apos;,&apos;0&apos;)</div><div class="line">    testline = testline.lower()</div><div class="line">    return testline</div><div class="line"></div><div class="line">def changeToWords(sentence):</div><div class="line">    global stopwords</div><div class="line">    out = translate(sentence)</div><div class="line">    jiebalistnew = []</div><div class="line">    jiebalist = jieba.lcut(out)</div><div class="line">    for item in jiebalist:</div><div class="line">        if item not in stopwords:#去除停用词</div><div class="line">            jiebalistnew = jiebalistnew + handlenum(item)</div><div class="line">    </div><div class="line">    if &apos;&apos; in jiebalistnew:</div><div class="line">        jiebalistnew.remove(&apos;&apos;) </div><div class="line">    if &apos; &apos; in jiebalistnew:</div><div class="line">        jiebalistnew.remove(&apos; &apos;)     </div><div class="line">    string = &apos; &apos;.join(jiebalistnew)</div><div class="line">#     return string,jiebalistnew</div><div class="line">    return string</div></pre></td></tr></table></figure>
<p>仔细看translate主要作用就是去除一些特殊字符，同时对大写数字进行转化，这个一个广告识别的预处理，因为好多广告要留下来号码什么的。</p>
<h3 id="抽取特征"><a href="#抽取特征" class="headerlink" title="抽取特征"></a>抽取特征</h3><p>抽取特征呢，主要是形成一个词典，然后把每句话对应到词典里的词，存在就是1，不存在就是0，通过这种方式把每句话转换成10100001这种向量。</p>
<h4 id="我们应该输入什么，输出的又是什么"><a href="#我们应该输入什么，输出的又是什么" class="headerlink" title="我们应该输入什么，输出的又是什么"></a>我们应该输入什么，输出的又是什么</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"> #该类会统计每个词语的tf-idf权值</div><div class="line">transformer = TfidfTransformer()</div><div class="line">vectorizer = CountVectorizer(token_pattern=u&apos;(?u)\w+&apos;)</div><div class="line">#第一个fit_transform是计算tf-idf 第二个fit_transform是将文本转为词频矩阵</div><div class="line">count0 = vectorizer.fit_transform(inputList)</div><div class="line">tfidf = transformer.fit_transform(count0)</div></pre></td></tr></table></figure>
<p>看一下上边的代码，我们的输入是inputList，那么这个变量明显就是我们的一个个的句子了，这是list类型，每个元素是一个句子，如果是英文文本，这样直接输入就好了，但是中文要进行一个转换，参照英文的样式，用空格分隔开，所以输入是下边这样的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">inputList = [&apos;我 爱 中国&apos;,&apos;我 是 中国人&apos;]</div></pre></td></tr></table></figure></p>
<p>输出：</p>
<p>特征提取，输出的当然是特征了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">transformer = TfidfTransformer()</div><div class="line">vectorizer = CountVectorizer(token_pattern=u&apos;(?u)\w+&apos;)</div><div class="line">count0 = vectorizer.fit_transform(pos)</div><div class="line">tran = transformer.fit_transform(count0)</div><div class="line"></div><div class="line"></div><div class="line">print vectorizer.vocabulary_ #这个字典里边存储了我们的关键字，以关键词为key，然后后边的value是它在向量字典里边的位置索引</div><div class="line">names = vectorizer.get_feature_names() #这个就是我们的向量词典了</div><div class="line">print count0.toarray() #这个是将为本转换为了向量，比如[0,2,1,2]2呢代表出现了两次</div><div class="line"></div><div class="line"></div><div class="line">for item in names:</div><div class="line">    print item</div><div class="line">sumlist = list(count0.toarray().sum(axis=0))#这里呢是将所有的词以及出现的次数进行了加和，看看每个词一共出现了多少次，后边两行代码都是为了这个事</div><div class="line"></div><div class="line">a1 = np.array([names,sumlist])</div><div class="line">a1 = np.transpose(a1)</div><div class="line">df = DataFrame(a1,columns=[&apos;name&apos;,&apos;count&apos;])</div></pre></td></tr></table></figure>
<h4 id="token提取规则"><a href="#token提取规则" class="headerlink" title="token提取规则"></a>token提取规则</h4><p>这个说的是<code>token_pattern</code>这个参数，它决定了每个单独的特征是如何提取的，如果你不赋值，这个初始值是<code>&#39;(?u)\\b\\w\\w+\b&#39;</code>意思是，提取字符加空格，所以我们用空格来区分，但是这个有个坑，默认是提取两个以上的字符，这就意味着如果你的一些特征只有一个字符那么这个特征就被自动忽略了，因为我们已经有了停用词去除机制，所以这里尽量做个修改，<code>token_pattern=u&#39;(?u)\w+&#39;</code>这样写就能够提取一个的中文了，网上基本上都在说英文咋整，难道大家做的都是英文的文本分类….中文的表示心累…</p>
<h4 id="最大特征数"><a href="#最大特征数" class="headerlink" title="最大特征数"></a>最大特征数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vectorizer = CountVectorizer(token_pattern=u&apos;(?u)\w+&apos;，max_features=200)</div></pre></td></tr></table></figure>
<p>这个值可以和去除低频词是异曲同工，如果我们经过分析发现特征词有1000个，然后低频是300，这样直接设置这个值是700就好了，它会自动选取最高频的700个词作为特征</p>
<h3 id="训练模型以及使用模型"><a href="#训练模型以及使用模型" class="headerlink" title="训练模型以及使用模型"></a>训练模型以及使用模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">pos = [u&apos;i&apos;,u&apos;中国/爱你 中国&apos;,u&apos;中国)爱谁 asf i&apos;,u&apos;我+爱你&apos;,u&apos;我+爱你&apos;]</div><div class="line"># pos = [&apos;this is a dog&apos;,&apos;the dog is cute,oh lovely dog&apos;,&apos;my dauter is smiling&apos;]</div><div class="line"># pos = [&apos;i love you&apos;, &apos;i hate you&apos;, &apos;i&apos;]</div><div class="line">#该类会统计每个词语的tf-idf权值</div><div class="line">transformer = TfidfTransformer()</div><div class="line">vectorizer = CountVectorizer(analyzer=&apos;word&apos;,token_pattern=u&apos;(?u)\w+&apos;)</div><div class="line"># u&apos;(?u)\\b\\w\\w+\\b&apos;</div><div class="line"># vectorizer = CountVectorizer()</div><div class="line">#第一个fit_transform是计算tf-idf 第二个fit_transform是将文本转为词频矩阵</div><div class="line">count0 = vectorizer.fit_transform(pos)</div><div class="line">tran = transformer.fit_transform(count0)</div><div class="line"></div><div class="line">x = weight</div><div class="line">y = np.concatenate((np.zeros(len(poscorpus)), np.ones(len(negcorpus))))</div><div class="line">    </div><div class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)</div><div class="line">    </div><div class="line">modelnew = MultinomialNB()</div><div class="line">modelnew.fit(x_train, y_train)</div><div class="line">scorenew = modelnew.score(x_test, y_test)</div><div class="line">print scorenew</div><div class="line">print &apos;donetest&apos;</div><div class="line"></div><div class="line"></div><div class="line">##必须要保存三个东西，一个是训练之后的模型，然后是</div><div class="line">joblib.dump(modelnew, &apos;bayes.pkl&apos;)</div><div class="line">joblib.dump(transformer, &apos;transformer&apos;)  # 保存分类器</div><div class="line">joblib.dump(vectorizer, &apos;vectorizer&apos;)  # 保存分类器</div><div class="line"></div><div class="line">print vectorizer.vocabulary_</div><div class="line">print count0.toarray()</div><div class="line"></div><div class="line">## 这里用于新数据的预测，我们需要训练好的模型，vec，tran这三个东西</div><div class="line">modelnew = joblib.load(&apos;bayes.pkl&apos;)</div><div class="line">transformer1 = joblib.load(&apos;transformer&apos;)</div><div class="line">vectorizer1 = joblib.load(&apos;vectorizer&apos;)</div><div class="line"></div><div class="line">CountVectorizer(vocabulary=vectorizer.vocabulary_,analyzer=&apos;word&apos;,token_pattern=u&apos;(?u)\w+&apos;) #注意这个会去除特殊字符</div><div class="line">count1 = vectorizer1.transform([u&apos;中国/爱你 中国&apos;])</div><div class="line">tran1 = transformer1.transform(count1)</div></pre></td></tr></table></figure>
<p>注意训练用<code>fit_transform</code>，而使用的时候我们用的是<code>transform</code></p>
<h3 id="模型的改进方法"><a href="#模型的改进方法" class="headerlink" title="模型的改进方法"></a>模型的改进方法</h3><blockquote>
<p>例如可以调节如下一些参数，观察它们对垃圾邮件过滤的实际效果的影响：</p>
</blockquote>
<ul>
<li><p>训练数据的大小</p>
</li>
<li><p>词典的大小</p>
</li>
<li><p>不同的机器学习模型，包括 GaussianNB，BernoulliNB，SVC</p>
</li>
<li><p>不同的 SVM 模型参数</p>
</li>
<li><p>删除无关紧要的词来改进词典 （例如手动删除）</p>
</li>
<li><p>采用其他特征模型 （寻找 td-idf）</p>
</li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag">#python</a>
          
            <a href="/tags/sklearn/" rel="tag">#sklearn</a>
          
            <a href="/tags/文本分类/" rel="tag">#文本分类</a>
          
            <a href="/tags/自然语言/" rel="tag">#自然语言</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/02/机器学习-文本分类/" rel="next" title="机器学习-文本分类">
                <i class="fa fa-chevron-left"></i> 机器学习-文本分类
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/19/skleanrn文本分类代码记录/" rel="prev" title="skleanrn文本分类代码记录">
                skleanrn文本分类代码记录 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
         <div id="uyan_frame"></div>
    
  </div>

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Hanson" />
          <p class="site-author-name" itemprop="name">Hanson</p>
          <p class="site-description motion-element" itemprop="description">数据挖掘，iOS，python，现在就职业京东金融</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">106</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">39</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#去除停用词和低频词"><span class="nav-number">1.</span> <span class="nav-text">去除停用词和低频词</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#抽取特征"><span class="nav-number">2.</span> <span class="nav-text">抽取特征</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#我们应该输入什么，输出的又是什么"><span class="nav-number">2.1.</span> <span class="nav-text">我们应该输入什么，输出的又是什么</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#token提取规则"><span class="nav-number">2.2.</span> <span class="nav-text">token提取规则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最大特征数"><span class="nav-number">2.3.</span> <span class="nav-text">最大特征数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练模型以及使用模型"><span class="nav-number">3.</span> <span class="nav-text">训练模型以及使用模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模型的改进方法"><span class="nav-number">4.</span> <span class="nav-text">模型的改进方法</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hanson</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  




  
    
  
 
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2148265"></script>
      <!-- UY END -->
  


  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = decodeURIComponent(data.url);
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  

  


</body>
</html>
