<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python,爬虫," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2" />






<meta name="description" content="这里主要实现的是利用爬虫来实现对关注指数基金的估值数据的抓取，然后进行估值分析，配合云服务器并且每天进行推送。 爬虫的基本步骤很简单，将该网页的js和html全部下载下来，然后从其中寻找有用的信息，进而将有用的信息进行结构化的存储，其中将网页爬取下来使用的scrapy，而寻找信息我们使用的是xpath，存储我们使用mongo">
<meta name="keywords" content="python,爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="爬虫系列">
<meta property="og:url" content="/2017/02/10/2017/爬虫系列/index.html">
<meta property="og:site_name" content="Hanson的博客">
<meta property="og:description" content="这里主要实现的是利用爬虫来实现对关注指数基金的估值数据的抓取，然后进行估值分析，配合云服务器并且每天进行推送。 爬虫的基本步骤很简单，将该网页的js和html全部下载下来，然后从其中寻找有用的信息，进而将有用的信息进行结构化的存储，其中将网页爬取下来使用的scrapy，而寻找信息我们使用的是xpath，存储我们使用mongo">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2017-06-08T01:45:50.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="爬虫系列">
<meta name="twitter:description" content="这里主要实现的是利用爬虫来实现对关注指数基金的估值数据的抓取，然后进行估值分析，配合云服务器并且每天进行推送。 爬虫的基本步骤很简单，将该网页的js和html全部下载下来，然后从其中寻找有用的信息，进而将有用的信息进行结构化的存储，其中将网页爬取下来使用的scrapy，而寻找信息我们使用的是xpath，存储我们使用mongo">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="/2017/02/10/2017/爬虫系列/"/>


  <title> 爬虫系列 | Hanson的博客 </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Hanson的博客</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                爬虫系列
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-02-10T12:56:37+08:00" content="2017-02-10">
              2017-02-10
            </time>
          </span>

          

          
            
          

          

          
          

          
              &nbsp; | &nbsp;
              <span class="page-pv"><i class="fa fa-file-o"></i>
              <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
              </span>
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这里主要实现的是利用爬虫来实现对关注指数基金的估值数据的抓取，然后进行估值分析，配合云服务器并且每天进行推送。</p>
<p>爬虫的基本步骤很简单，将该网页的js和html全部下载下来，然后从其中寻找有用的信息，进而将有用的信息进行结构化的存储，其中将网页爬取下来使用的scrapy，而寻找信息我们使用的是xpath，存储我们使用mongo<br><a id="more"></a></p>
<h3 id="使用scrapy框架"><a href="#使用scrapy框架" class="headerlink" title="使用scrapy框架"></a>使用scrapy框架</h3><ul>
<li><p>安装<br><code>sudo pip install scrapy</code>或者直接下载源码，自己编译*下载0.24版本的scrapy<a href="http://scrapy.org/download/" target="_blank" rel="external">http://scrapy.org/download/</a><br>然后cd 进入解压后的文件，然后执行sudo python setup.py install安装scrapy</p>
<blockquote>
<p>如果在使用命令行过程中发现sudo之后仍然无法获取权限，删除文件时会提示Operation not permitted，那就关机重启，然后按住comman+R，启动之后启动命令行，输入，csrutil disable关闭rootless就可以了</p>
</blockquote>
</li>
<li><p>scrapy startproject tutorial创建爬虫工程</p>
</li>
</ul>
<ul>
<li>scrapy.cfg: 项目的配置文件</li>
<li>tutorial/: 该项目的python模块。之后您将在此加入代码。</li>
<li>tutorial/items.py: 项目中的item文件.</li>
<li>tutorial/pipelines.py: 项目中的pipelines文件.</li>
<li>tutorial/settings.py: 项目的设置文件.</li>
<li>tutorial/spiders/: 放置spider代码的目录.</li>
</ul>
<blockquote>
<p>文件作用说明</p>
</blockquote>
<ul>
<li>items.py：定义后期处理的数据，是一个容器，像一个字典</li>
<li>settings.py：配置scrapy，从而修改user-agent,设置爬取时间，设置代理，设置中间件</li>
<li>pipelines.py:用于存放执行后去数据处理的功能，从而把爬取与处理分开<br>item成功获取数据之后，它会送到pipeline，让pipeline对数据进行处理</li>
</ul>
<p>运行工程：<br>scrapy目前只能使用命令行来运行<code>scrapy crawl demo</code>这里要注意的是后边的这个demo这个名字不是随便来的，spider这个文件命名要是demo_spider才可以</p>
<h3 id="xpath的使用"><a href="#xpath的使用" class="headerlink" title="xpath的使用"></a>xpath的使用</h3><p>用到的工具：</p>
<ul>
<li>火狐浏览器</li>
<li>FirePath插件</li>
<li>Firebug插件</li>
<li>XPath Checker插件</li>
</ul>
<p>1.右键选择－Inspect in FirePath<br>2.复制xpath<br>3.在该页面上右键－&gt;View XPath<br>4.把xpath的路径复制进入该页面，查看是否能够找到自己想要的元素</p>
<h3 id="mongodb的安装以及使用"><a href="#mongodb的安装以及使用" class="headerlink" title="mongodb的安装以及使用"></a>mongodb的安装以及使用</h3><ul>
<li><p>一行代码安装mongodbbrew install mongoDB前提是已经安装了brew工具，一次失败就执行第二次<br>*<br>如果上边的方法还是不行，那就只能手动下载了</p>
<ul>
<li><a href="https://fastdl.mongodb.org/osx/mongodb-osx-x86_64-3.2.3.tgz" target="_blank" rel="external">https://fastdl.mongodb.org/osx/mongodb-osx-x86_64-3.2.3.tgz</a></li>
<li>命令行解压该包tar xzvf mongodb-osx-x86_64-3.2.3.tgz</li>
<li>将解压后的文件放到一个可以长期放置的地方，然后进入该文件夹</li>
<li>pwd记录当前文件路径，copy一下，一会儿有用</li>
<li>vim ~/.zshrc进入配置目录<br><em><br>#mongod config<br>MONGODB_HOME=/Users/shenghuihan/Desktop/mongodb-osx-x86_64-3.2.3<br>PATH=$PATH:$MONGODB_HOME/bin添加bin目录文件到系统搜索目录下
</em><br>source ~/.zshrc使设置生效</li>
</ul>
</li>
<li>查看mongo是否生效mongo，如果显示版本号说明生效，但是没有启动下面我们来启动服务</li>
<li>先在同级目录下创建数据文件和日志文件mkdir data和mkdir log</li>
<li>启动mongodb服务mongod –dbpath data –logpath log/mongod.log –logappend –fork</li>
<li>再次mongo如果显示connecting to test说明启动成功，输入exit;退出mongo</li>
<li>将启动命令写入一个启动脚本中echo “mongod –dbpath data –logpath log/mongod.log –logappend –fork” &gt;&gt; start.sh</li>
<li>可视化工具安装<a href="https://mongohub.s3.amazonaws.com/MongoHub.zip直接去这里下载" target="_blank" rel="external">https://mongohub.s3.amazonaws.com/MongoHub.zip直接去这里下载</a></li>
<li>安装python操作mongodb的驱动sudo pip install pymongo前提是要安装pip啊，这是一个专门用来安装python各种库的软件</li>
<li>默认端口27017</li>
<li>查看ip的方式，db.getMongo()</li>
</ul>
<h4 id="使用mongodb命令行"><a href="#使用mongodb命令行" class="headerlink" title="使用mongodb命令行"></a>使用mongodb命令行</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">bogon:mongo shenghuihan$ mongo</div><div class="line">MongoDB shell version: 3.2.3</div><div class="line">connecting to: test</div><div class="line">Server has startup warnings: </div><div class="line">2016-09-08T17:51:01.057+0800 I CONTROL  [initandlisten] </div><div class="line">2016-09-08T17:51:01.057+0800 I CONTROL  [initandlisten] ** WARNING: soft rlimits too low. Number of files is 256, should be at least 1000</div><div class="line">&gt; use mydb//创建一个新的库</div><div class="line">switched to db mydb</div><div class="line">&gt; show collections</div><div class="line">&gt; show dbs</div></pre></td></tr></table></figure>
<h4 id="使用以及查看数据"><a href="#使用以及查看数据" class="headerlink" title="使用以及查看数据"></a>使用以及查看数据</h4><p>我们可以使用mongohub查看数据，当然还可以使用我们最喜欢的python<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">import pymongo</div><div class="line"></div><div class="line">connection = pymongo.MongoClient()</div><div class="line">tdb = connection.jikexueyuan</div><div class="line">post_info = tdb.ceshi</div><div class="line"></div><div class="line">jike = &#123;&apos;name&apos;:u&apos;哈哈哈&apos;&#125;#插入数据</div><div class="line">goog = &#123;&apos;name&apos;:u&apos;校长&apos;&#125;</div><div class="line"></div><div class="line"># post_info.insert(jike)</div><div class="line"># post_info.insert(goog)</div><div class="line">post_info.remove(&#123;&apos;name&apos;:u&apos;校长&apos;&#125;)</div><div class="line"></div><div class="line">print u&apos;操作完成&apos;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">from pymongo import MongoClient</div><div class="line"></div><div class="line">mc = MongoClient(&quot;localhost&quot;,27017)</div><div class="line"></div><div class="line">db = mc.users</div><div class="line"></div><div class="line">c = db.users.find()</div><div class="line"></div><div class="line">db.users.save(&#123;&quot;age&quot;:8&#125;)</div><div class="line"></div><div class="line">for objc in c:</div><div class="line">    print(objc)</div><div class="line"></div><div class="line">mc.close()</div></pre></td></tr></table></figure>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag">#python</a>
          
            <a href="/tags/爬虫/" rel="tag">#爬虫</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/01/17/2017/Lunix云服务器折腾小记/" rel="next" title="Lunix云服务器折腾小记">
                <i class="fa fa-chevron-left"></i> Lunix云服务器折腾小记
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/02/16/2017/指数自动获取/" rel="prev" title="指数自动获取">
                指数自动获取 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Hanson" />
          <p class="site-author-name" itemprop="name">Hanson</p>
          <p class="site-description motion-element" itemprop="description">iOS开发者，python/js爱好者，现在就职业京东金融</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">70</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">24</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#使用scrapy框架"><span class="nav-number">1.</span> <span class="nav-text">使用scrapy框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#xpath的使用"><span class="nav-number">2.</span> <span class="nav-text">xpath的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#mongodb的安装以及使用"><span class="nav-number">3.</span> <span class="nav-text">mongodb的安装以及使用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用mongodb命令行"><span class="nav-number">3.1.</span> <span class="nav-text">使用mongodb命令行</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用以及查看数据"><span class="nav-number">3.2.</span> <span class="nav-text">使用以及查看数据</span></a></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hanson</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = decodeURIComponent(data.url);
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  

  


</body>
</html>
